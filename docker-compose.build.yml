services:
  discord-llm-bot:
    pull_policy: build
    build:
      context: ./bot
      dockerfile: Dockerfile.client
      network: host
    container_name: discord-bot
    network_mode: host
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Europe/Rome
    volumes:
      - ".env:/app/.env"
      - "./config:/app/config"
      - "./audios:/app/audios"
      - "./models:/app/models"
      - "/tmp/discord-llm-bot:/tmp/discord-llm-bot"
      - /dev/dri/card0:/dev/dri/card0
      - /dev/dri/card1:/dev/dri/card1
      - /dev/dri/card2:/dev/dri/card2
      - /dev/dri/renderD128:/dev/dri/renderD128
    image: "blastbeng/discord-llm-bot:1.0.0"
    restart: unless-stopped
  telegram-llm-bot:
    pull_policy: build
    build:
      context: ./bot
      dockerfile: Dockerfile.telegram
      network: host
    container_name: telegram-bot
    network_mode: host
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Europe/Rome
    volumes:
      - ".env:/app/.env"
      - "./config:/app/config"
      - "./models:/app/models"
      - "/tmp/discord-llm-bot:/tmp/discord-llm-bot"
      - /dev/dri/card0:/dev/dri/card0
      - /dev/dri/card1:/dev/dri/card1
      - /dev/dri/card2:/dev/dri/card2
      - /dev/dri/renderD128:/dev/dri/renderD128
    image: "blastbeng/telegram-llm-bot:1.0.0"
    restart: unless-stopped
  llama_cpp:
    container_name: llama_cpp
    pull_policy: build
    build:
      context: ./llama.cpp
      dockerfile: .devops/vulkan.Dockerfile
      network: host
    environment:
      - PUID=1000
      - PGID=1000
    volumes:
      - ./models:/models
      - /dev/dri/renderD128:/dev/dri/renderD128
      - /dev/dri/card0:/dev/dri/card0
      - /dev/dri/card1:/dev/dri/card1
      - /dev/dri/card2:/dev/dri/card2s
    ports:
      - 8080:8080
    image: "blastbeng/llama_cpp:1.0.0"
    restart: unless-stopped